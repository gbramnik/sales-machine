<!-- Powered by BMAD™ Core -->

# Story 2.4: Humanness Testing Framework

## Status
Draft

## Story
**As a** product manager,
**I want** to validate AI messages are perceived as human,
**so that** we achieve <20% detection rate (NFR5) before scaling.

## Dependencies
- **Story 1.6** (Basic AI Conversational Agent) MUST be completed - AI agent workflow and message generation
- **Story 1.4** (Proven Email Template Library) MUST be completed - Template library for codifying winning strategy
- **Story 2.1** (AI Confidence Scoring System) SHOULD be completed - Analytics infrastructure for tracking
- **Story 1.3** (AI-Powered Contextual Enrichment) SHOULD be completed - Enrichment data for realistic test messages

## Acceptance Criteria
1. Recruit 10 B2B decision-makers matching ICP (French SMB owners/founders) for perception panel
2. Test design: Show 10 messages (5 AI-generated, 5 human-written), ask to identify which are AI
3. Target: <20% correct AI identification rate (indistinguishable from human baseline)
4. Variants tested: Generate 5 different AI prompting strategies, identify lowest detection rate
5. Winning strategy codified into template library and AI prompts
6. Post-launch tracking: User survey quarterly "Have prospects mentioned detecting automation?" (target <5% yes)
7. Response rate proxy: Track reply rate per 100 messages (if drops below 5% for cold, investigate AI fatigue)

## Tasks / Subtasks

- [ ] **Task 1: Create humanness test database schema** (AC: 1, 2, 4)
  - [ ] Create table: `humanness_tests`
    - Migration: `supabase/migrations/YYYYMMDD_create_humanness_tests.sql`
    - Schema:
      ```sql
      CREATE TABLE public.humanness_tests (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        test_name TEXT NOT NULL,
        test_version TEXT NOT NULL,
        test_type TEXT NOT NULL CHECK (test_type IN ('perception_panel', 'post_launch_survey', 'response_rate_tracking')),
        status TEXT DEFAULT 'draft' CHECK (status IN ('draft', 'active', 'completed', 'archived')),
        target_detection_rate DECIMAL(5,2) DEFAULT 20.00, -- Target <20%
        created_at TIMESTAMPTZ DEFAULT NOW(),
        completed_at TIMESTAMPTZ,
        created_by UUID REFERENCES public.users(id) ON DELETE SET NULL,
        metadata JSONB DEFAULT '{}'::jsonb -- Store test configuration
      );
      CREATE INDEX idx_humanness_tests_status ON public.humanness_tests(status);
      CREATE INDEX idx_humanness_tests_type ON public.humanness_tests(test_type);
      ```
  - [ ] Create table: `humanness_test_messages`
    - Migration: `supabase/migrations/YYYYMMDD_create_humanness_test_messages.sql`
    - Schema:
      ```sql
      CREATE TABLE public.humanness_test_messages (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        test_id UUID REFERENCES public.humanness_tests(id) ON DELETE CASCADE,
        message_text TEXT NOT NULL,
        message_type TEXT NOT NULL CHECK (message_type IN ('ai_generated', 'human_written')),
        ai_prompting_strategy TEXT, -- NULL for human_written, strategy name for AI (e.g., 'strategy_1', 'strategy_2')
        channel TEXT NOT NULL CHECK (channel IN ('linkedin', 'email')),
        subject TEXT, -- NULL for LinkedIn, required for email
        template_id UUID REFERENCES public.email_templates(id) ON DELETE SET NULL, -- If AI used template
        created_at TIMESTAMPTZ DEFAULT NOW(),
        metadata JSONB DEFAULT '{}'::jsonb -- Store enrichment context, prospect details used
      );
      CREATE INDEX idx_humanness_test_messages_test_id ON public.humanness_test_messages(test_id);
      CREATE INDEX idx_humanness_test_messages_type ON public.humanness_test_messages(message_type);
      CREATE INDEX idx_humanness_test_messages_strategy ON public.humanness_test_messages(ai_prompting_strategy);
      ```
  - [ ] Create table: `humanness_test_responses`
    - Migration: `supabase/migrations/YYYYMMDD_create_humanness_test_responses.sql`
    - Schema:
      ```sql
      CREATE TABLE public.humanness_test_responses (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        test_id UUID REFERENCES public.humanness_tests(id) ON DELETE CASCADE,
        panelist_id UUID REFERENCES public.humanness_test_panelists(id) ON DELETE CASCADE,
        message_id UUID REFERENCES public.humanness_test_messages(id) ON DELETE CASCADE,
        identified_as_ai BOOLEAN NOT NULL, -- True if panelist identified message as AI
        confidence_level INTEGER CHECK (confidence_level >= 1 AND confidence_level <= 5), -- 1=very unsure, 5=very confident
        reasoning TEXT, -- Optional: Why they identified it as AI/human
        response_time_seconds INTEGER, -- Time taken to respond
        created_at TIMESTAMPTZ DEFAULT NOW()
      );
      CREATE INDEX idx_humanness_test_responses_test_id ON public.humanness_test_responses(test_id);
      CREATE INDEX idx_humanness_test_responses_panelist_id ON public.humanness_test_responses(panelist_id);
      CREATE INDEX idx_humanness_test_responses_message_id ON public.humanness_test_responses(message_id);
      ```
  - [ ] Create table: `humanness_test_panelists`
    - Migration: `supabase/migrations/YYYYMMDD_create_humanness_test_panelists.sql`
    - Schema:
      ```sql
      CREATE TABLE public.humanness_test_panelists (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        test_id UUID REFERENCES public.humanness_tests(id) ON DELETE CASCADE,
        full_name TEXT NOT NULL,
        email TEXT NOT NULL,
        job_title TEXT,
        company_name TEXT,
        company_size TEXT CHECK (company_size IN ('1-10', '11-50', '51-200', '201-500', '500+')),
        industry TEXT,
        country TEXT DEFAULT 'FR', -- Target: French SMB owners/founders
        role TEXT CHECK (role IN ('owner', 'founder', 'ceo', 'cto', 'cmo', 'decision_maker')),
        recruitment_status TEXT DEFAULT 'pending' CHECK (recruitment_status IN ('pending', 'invited', 'accepted', 'completed', 'declined')),
        invitation_sent_at TIMESTAMPTZ,
        test_completed_at TIMESTAMPTZ,
        compensation_offered TEXT, -- e.g., "€50 Amazon voucher"
        created_at TIMESTAMPTZ DEFAULT NOW(),
        UNIQUE(test_id, email)
      );
      CREATE INDEX idx_humanness_test_panelists_test_id ON public.humanness_test_panelists(test_id);
      CREATE INDEX idx_humanness_test_panelists_status ON public.humanness_test_panelists(recruitment_status);
      ```
  - [ ] Create table: `humanness_test_analytics`
    - Migration: `supabase/migrations/YYYYMMDD_create_humanness_test_analytics.sql`
    - Schema:
      ```sql
      CREATE TABLE public.humanness_test_analytics (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        test_id UUID REFERENCES public.humanness_tests(id) ON DELETE CASCADE,
        ai_prompting_strategy TEXT, -- NULL for overall metrics
        total_messages INTEGER NOT NULL,
        ai_messages_count INTEGER NOT NULL,
        human_messages_count INTEGER NOT NULL,
        ai_correctly_identified INTEGER NOT NULL DEFAULT 0, -- How many AI messages were correctly identified as AI
        ai_incorrectly_identified_as_human INTEGER NOT NULL DEFAULT 0, -- AI messages identified as human (good!)
        human_incorrectly_identified_as_ai INTEGER NOT NULL DEFAULT 0, -- Human messages identified as AI (false positive)
        detection_rate DECIMAL(5,2) NOT NULL, -- Percentage: (ai_correctly_identified / ai_messages_count) * 100
        false_positive_rate DECIMAL(5,2) NOT NULL, -- Percentage: (human_incorrectly_identified_as_ai / human_messages_count) * 100
        calculated_at TIMESTAMPTZ DEFAULT NOW(),
        UNIQUE(test_id, ai_prompting_strategy)
      );
      CREATE INDEX idx_humanness_test_analytics_test_id ON public.humanness_test_analytics(test_id);
      CREATE INDEX idx_humanness_test_analytics_strategy ON public.humanness_test_analytics(ai_prompting_strategy);
      ```

- [ ] **Task 2: Implement panelist recruitment system** (AC: 1)
  - [ ] Create service: `apps/api/src/services/HumannessTestService.ts`
  - [ ] Implement `createTest(testName: string, testVersion: string, userId: string): Promise<HumannessTest>`:
    - Insert into `humanness_tests` table
    - Set `status = 'draft'`, `test_type = 'perception_panel'`
    - Return: `{ id, test_name, test_version, status, ... }`
  - [ ] Implement `addPanelist(testId: string, panelistData: PanelistData): Promise<Panelist>`:
    - Input: `{ full_name, email, job_title, company_name, company_size, industry, country, role }`
    - Validate: Email format, required fields
    - Insert into `humanness_test_panelists` table
    - Set `recruitment_status = 'pending'`
    - Return: `{ id, full_name, email, recruitment_status, ... }`
  - [ ] Implement `sendPanelistInvitation(testId: string, panelistId: string): Promise<void>`:
    - Query panelist: Get email, full_name, test details
    - Generate invitation email:
      - Subject: "Invitation to participate in AI message perception study"
      - Body: Include test description, compensation offer, link to test interface
      - Test link: `{{ $env.WEB_APP_URL }}/humanness-test/{{ testId }}/panelist/{{ panelistId }}`
    - Send via SMTPService: `SMTPService.sendEmail({ to: panelist.email, subject, html: emailBody, from: 'research@no-spray-no-pray.com' })`
    - Update panelist: `recruitment_status = 'invited'`, `invitation_sent_at = NOW()`
  - [ ] Implement `bulkInvitePanelists(testId: string, panelistIds: string[]): Promise<BulkInviteResult>`:
    - For each panelist ID: Call `sendPanelistInvitation()`
    - Track success/failure for each
    - Return: `{ total: number, sent: number, failed: number, errors: Array<{ panelist_id, error }> }`
  - [ ] Create API endpoint: `POST /api/humanness-tests`
    - Location: `apps/api/src/routes/humanness-tests.ts` (new file)
    - Request body: `{ test_name: string, test_version: string }`
    - Validate: Use Zod schema: `z.object({ test_name: z.string().min(1).max(200), test_version: z.string().min(1).max(50) })`
    - Call: `HumannessTestService.createTest(testName, testVersion, userId)`
    - Return: `{ success: true, data: { test_id, test_name, status } }`
    - Add authentication middleware
  - [ ] Create API endpoint: `POST /api/humanness-tests/:id/panelists`
    - Location: `apps/api/src/routes/humanness-tests.ts`
    - Request body: `{ full_name, email, job_title, company_name, company_size, industry, country, role }`
    - Validate: Use Zod schema with all required fields
    - Call: `HumannessTestService.addPanelist(testId, panelistData)`
    - Return: `{ success: true, data: { panelist_id, full_name, email, recruitment_status } }`
  - [ ] Create API endpoint: `POST /api/humanness-tests/:id/panelists/:panelistId/invite`
    - Location: `apps/api/src/routes/humanness-tests.ts`
    - Call: `HumannessTestService.sendPanelistInvitation(testId, panelistId)`
    - Return: `{ success: true, message: "Invitation sent" }`
  - [ ] Create API endpoint: `POST /api/humanness-tests/:id/panelists/bulk-invite`
    - Location: `apps/api/src/routes/humanness-tests.ts`
    - Request body: `{ panelist_ids: string[] }`
    - Call: `HumannessTestService.bulkInvitePanelists(testId, panelistIds)`
    - Return: `{ success: true, data: { total, sent, failed, errors } }`

- [ ] **Task 3: Generate test messages with 5 AI prompting strategies** (AC: 2, 4)
  - [ ] Create service: `apps/api/src/services/HumannessTestMessageService.ts`
  - [ ] Implement `generateAIMessagesWithStrategies(testId: string, prospectContext: ProspectContext, userId: string): Promise<TestMessage[]>`:
    - Input: `{ prospect_id, enrichment_data, channel }` (use real prospect data for realism)
    - Generate 5 AI messages using different prompting strategies:
      - **Strategy 1: Baseline (current)** - Use existing AIQualificationService prompt (Story 1.6)
      - **Strategy 2: Conversational** - Add instruction: "Write as if you're a colleague having a casual conversation. Use contractions, natural pauses, and friendly tone."
      - **Strategy 3: Professional but warm** - Add instruction: "Write professionally but with warmth. Use 'I' statements, show genuine interest, avoid corporate jargon."
      - **Strategy 4: Short and direct** - Add instruction: "Keep message under 3 sentences. Be direct, no fluff. Get to the point quickly."
      - **Strategy 5: Question-led** - Add instruction: "Start with a genuine question about their business. Show curiosity, not sales pitch."
    - For each strategy:
      - Call AIQualificationService with enhanced prompt (temporarily modify prompt for this test)
      - Store generated message in `humanness_test_messages` with `message_type = 'ai_generated'`, `ai_prompting_strategy = 'strategy_1'|'strategy_2'|...`
      - Store `template_id` if template was used
      - Store `metadata` with enrichment context used
    - Return: Array of 5 AI-generated messages
  - [ ] Implement `generateHumanMessages(testId: string, prospectContext: ProspectContext, userId: string): Promise<TestMessage[]>`:
    - **Note:** Human messages should be written by product manager/user, not AI
    - Create API endpoint or manual input method for human message entry
    - Store in `humanness_test_messages` with `message_type = 'human_written'`, `ai_prompting_strategy = NULL`
    - Return: Array of 5 human-written messages
  - [ ] Implement `createTestMessageSet(testId: string, prospectContext: ProspectContext, userId: string): Promise<MessageSet>`:
    - Call `generateAIMessagesWithStrategies()` → 5 AI messages
    - Call `generateHumanMessages()` → 5 human messages (or prompt user to input)
    - Shuffle messages randomly (mix AI and human)
    - Store all 10 messages in `humanness_test_messages`
    - Return: `{ test_id, messages: Array<{ id, message_text, message_type, ai_prompting_strategy, order }> }`
  - [ ] Create API endpoint: `POST /api/humanness-tests/:id/generate-messages`
    - Location: `apps/api/src/routes/humanness-tests.ts`
    - Request body: `{ prospect_id: string, channel: 'linkedin' | 'email' }`
    - Validate: Use Zod schema
    - Get prospect context: Query `prospects` and `prospect_enrichment` tables
    - Call: `HumannessTestMessageService.createTestMessageSet(testId, prospectContext, userId)`
    - Return: `{ success: true, data: { message_set_id, messages: [...] } }`
  - [ ] Create API endpoint: `POST /api/humanness-tests/:id/human-messages`
    - Location: `apps/api/src/routes/humanness-tests.ts`
    - Request body: `{ messages: Array<{ message_text: string, subject?: string, channel: 'linkedin' | 'email' }> }`
    - Validate: Exactly 5 messages required
    - Call: `HumannessTestMessageService.generateHumanMessages(testId, prospectContext, userId)`
    - Return: `{ success: true, data: { messages: [...] } }`

- [ ] **Task 4: Create panelist test interface** (AC: 2)
  - [ ] **Frontend:** Create test interface page (if frontend exists)
    - Location: `apps/web/src/pages/HumannessTestPanelist.tsx` (new file)
    - Route: `/humanness-test/:testId/panelist/:panelistId`
    - **UI Flow:**
      1. Welcome screen: Explain test purpose, compensation, estimated time (5-10 minutes)
      2. Instructions: "You will see 10 messages. For each, indicate whether you think it was written by AI or a human."
      3. Message display: Show one message at a time (LinkedIn or Email format)
      4. Response form: Radio buttons "AI-generated" / "Human-written", optional confidence slider (1-5), optional reasoning text
      5. Progress indicator: "Message 3 of 10"
      6. Submit button: "Next" → "Submit Test"
      7. Thank you screen: "Thank you for participating. Your compensation will be sent to [email]."
    - **API Integration:**
      - `GET /api/humanness-tests/:testId/panelist/:panelistId/messages` - Get shuffled message set
      - `POST /api/humanness-tests/:testId/panelist/:panelistId/responses` - Submit response for one message
      - `POST /api/humanness-tests/:testId/panelist/:panelistId/complete` - Mark test as completed
  - [ ] Create API endpoint: `GET /api/humanness-tests/:testId/panelist/:panelistId/messages`
    - Location: `apps/api/src/routes/humanness-tests.ts`
    - Query `humanness_test_messages` for test_id, shuffle order (or use pre-shuffled order)
    - Return: `{ success: true, data: { messages: Array<{ id, message_text, subject, channel, order }> } }`
    - **Note:** Do NOT include `message_type` or `ai_prompting_strategy` in response (panelist shouldn't know)
  - [ ] Create API endpoint: `POST /api/humanness-tests/:testId/panelist/:panelistId/responses`
    - Location: `apps/api/src/routes/humanness-tests.ts`
    - Request body: `{ message_id: string, identified_as_ai: boolean, confidence_level?: number, reasoning?: string, response_time_seconds: number }`
    - Validate: Use Zod schema
    - Insert into `humanness_test_responses` table
    - Return: `{ success: true, message: "Response recorded" }`
  - [ ] Create API endpoint: `POST /api/humanness-tests/:testId/panelist/:panelistId/complete`
    - Location: `apps/api/src/routes/humanness-tests.ts`
    - Update panelist: `recruitment_status = 'completed'`, `test_completed_at = NOW()`
    - Trigger compensation email (if applicable)
    - Return: `{ success: true, message: "Test completed. Thank you!" }`

- [ ] **Task 5: Calculate detection rate analytics** (AC: 3, 4)
  - [ ] Create service: `apps/api/src/services/HumannessTestAnalyticsService.ts`
  - [ ] Implement `calculateDetectionRate(testId: string): Promise<DetectionRateMetrics>`:
    - Query `humanness_test_responses` JOIN `humanness_test_messages`:
      ```sql
      SELECT 
        htm.message_type,
        htm.ai_prompting_strategy,
        COUNT(*) as total_responses,
        SUM(CASE WHEN htr.identified_as_ai = true AND htm.message_type = 'ai_generated' THEN 1 ELSE 0 END) as ai_correctly_identified,
        SUM(CASE WHEN htr.identified_as_ai = false AND htm.message_type = 'ai_generated' THEN 1 ELSE 0 END) as ai_incorrectly_identified_as_human,
        SUM(CASE WHEN htr.identified_as_ai = true AND htm.message_type = 'human_written' THEN 1 ELSE 0 END) as human_incorrectly_identified_as_ai
      FROM humanness_test_responses htr
      JOIN humanness_test_messages htm ON htr.message_id = htm.id
      WHERE htm.test_id = $testId
      GROUP BY htm.message_type, htm.ai_prompting_strategy
      ```
    - Calculate metrics:
      - For each AI strategy:
        - `ai_messages_count`: Count of AI messages with this strategy
        - `ai_correctly_identified`: Count of AI messages correctly identified as AI
        - `detection_rate = (ai_correctly_identified / ai_messages_count) * 100`
        - `false_positive_rate = (human_incorrectly_identified_as_ai / human_messages_count) * 100`
      - Overall detection rate: Average across all strategies
    - Store in `humanness_test_analytics` table (upsert by test_id + strategy)
    - Return: `{ overall_detection_rate, strategy_metrics: Array<{ strategy, detection_rate, ai_messages_count, ai_correctly_identified }>, target_met: boolean }`
  - [ ] Implement `getWinningStrategy(testId: string): Promise<WinningStrategy>`:
    - Query `humanness_test_analytics` for test_id, order by `detection_rate ASC` (lowest = best)
    - Get strategy with lowest detection rate
    - Return: `{ strategy_name: string, detection_rate: number, ai_messages_count: number, ai_correctly_identified: number }`
  - [ ] Create API endpoint: `GET /api/humanness-tests/:id/analytics`
    - Location: `apps/api/src/routes/humanness-tests.ts`
    - Call: `HumannessTestAnalyticsService.calculateDetectionRate(testId)`
    - Return: `{ success: true, data: { overall_detection_rate, strategy_metrics: [...], target_met: boolean, winning_strategy: {...} } }`
  - [ ] Create API endpoint: `GET /api/humanness-tests/:id/winning-strategy`
    - Location: `apps/api/src/routes/humanness-tests.ts`
    - Call: `HumannessTestAnalyticsService.getWinningStrategy(testId)`
    - Return: `{ success: true, data: { strategy_name, detection_rate, ... } }`

- [ ] **Task 6: Codify winning strategy into template library and AI prompts** (AC: 5)
  - [ ] Create service: `apps/api/src/services/HumannessStrategyService.ts`
  - [ ] Implement `codifyWinningStrategy(testId: string, strategyName: string, userId: string): Promise<CodificationResult>`:
    - Get winning strategy details: Call `HumannessTestAnalyticsService.getWinningStrategy(testId)`
    - **Update AI prompts:**
      - Location: `apps/api/src/services/ai-qualification.service.ts` (Story 1.6)
      - Read current system prompt
      - Add winning strategy instructions to system prompt:
        - If `strategy_2` (Conversational): Add "Write as if you're a colleague having a casual conversation. Use contractions, natural pauses, and friendly tone."
        - If `strategy_3` (Professional but warm): Add "Write professionally but with warmth. Use 'I' statements, show genuine interest, avoid corporate jargon."
        - If `strategy_4` (Short and direct): Add "Keep message under 3 sentences. Be direct, no fluff. Get to the point quickly."
        - If `strategy_5` (Question-led): Add "Start with a genuine question about their business. Show curiosity, not sales pitch."
      - **Note:** Store strategy in config or environment variable, don't hardcode
    - **Create VIP-style templates:**
      - Location: `supabase/migrations/YYYYMMDD_seed_humanness_winning_templates.sql`
      - Create email templates based on winning strategy:
        - If conversational: Create templates with casual tone, contractions
        - If professional but warm: Create templates with "I" statements, genuine interest
        - If short and direct: Create templates with <3 sentences
        - If question-led: Create templates starting with questions
      - Insert into `email_templates` table with `is_vip_template = FALSE` (these are for all messages)
      - Mark with `metadata.humanness_strategy = 'strategy_X'` in JSONB field
    - **Update template selection logic:**
      - Location: `apps/api/src/services/email-template.service.ts` (Story 1.4)
      - Update `getTemplate()` or `getTemplatesForChannel()` to prefer templates with `metadata.humanness_strategy = winning_strategy`
      - Or: Create new method `getHumannessOptimizedTemplates(channel: string, userId: string)`
    - Log codification: Insert into `audit_log`: `{ event_type: 'humanness_strategy_codified', test_id, strategy_name, detection_rate }`
    - Return: `{ success: true, strategy_codified: strategyName, templates_created: number, prompts_updated: boolean }`
  - [ ] Create API endpoint: `POST /api/humanness-tests/:id/codify-strategy`
    - Location: `apps/api/src/routes/humanness-tests.ts`
    - Request body: `{ strategy_name: string }` (optional, defaults to winning strategy)
    - Call: `HumannessStrategyService.codifyWinningStrategy(testId, strategyName, userId)`
    - Return: `{ success: true, data: { strategy_codified, templates_created, prompts_updated } }`
    - Add authentication middleware

- [ ] **Task 7: Implement post-launch survey tracking** (AC: 6)
  - [ ] Create table: `humanness_post_launch_surveys`
    - Migration: `supabase/migrations/YYYYMMDD_create_humanness_post_launch_surveys.sql`
    - Schema:
      ```sql
      CREATE TABLE public.humanness_post_launch_surveys (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        user_id UUID REFERENCES public.users(id) ON DELETE CASCADE,
        survey_period TEXT NOT NULL, -- e.g., "2025-Q1", "2025-Q2"
        question_1_detection_mentioned BOOLEAN, -- "Have prospects mentioned detecting automation?"
        question_1_details TEXT, -- Optional: Details if yes
        question_2_response_rate DECIMAL(5,2), -- Response rate per 100 messages
        question_3_feedback TEXT, -- Optional: General feedback
        submitted_at TIMESTAMPTZ DEFAULT NOW(),
        UNIQUE(user_id, survey_period)
      );
      CREATE INDEX idx_humanness_post_launch_surveys_user_id ON public.humanness_post_launch_surveys(user_id);
      CREATE INDEX idx_humanness_post_launch_surveys_period ON public.humanness_post_launch_surveys(survey_period);
      ```
  - [ ] Create N8N workflow: `workflows/humanness-survey-notifier.json`
    - Schedule trigger: Cron `0 0 1 */3 *` (runs quarterly on 1st of month: Jan, Apr, Jul, Oct)
    - Query all active users: `SELECT id, email, full_name FROM users WHERE subscription_status = 'active'`
    - For each user:
      - Check if survey already submitted for current quarter: Query `humanness_post_launch_surveys` for `user_id` and current `survey_period`
      - If not submitted: Send survey email
        - Subject: "Quarterly AI Message Quality Survey - [Quarter]"
        - Body: Include survey questions and link: `{{ $env.WEB_APP_URL }}/humanness-survey?user_id={{ $json.id }}&period={{ $json.current_period }}`
        - Send via SMTPService
  - [ ] Create API endpoint: `POST /api/humanness-surveys`
    - Location: `apps/api/src/routes/humanness-surveys.ts` (new file)
    - Request body: `{ survey_period: string, question_1_detection_mentioned: boolean, question_1_details?: string, question_2_response_rate?: number, question_3_feedback?: string }`
    - Validate: Use Zod schema
    - Insert/update `humanness_post_launch_surveys` table (upsert by user_id + survey_period)
    - Calculate target: `detection_mentioned_rate = (COUNT WHERE question_1_detection_mentioned = true) / (COUNT total) * 100`
    - If `detection_mentioned_rate > 5%`: Log alert to `audit_log`: `{ event_type: 'humanness_survey_alert', detection_rate: number, threshold: 5 }`
    - Return: `{ success: true, message: "Survey submitted" }`
  - [ ] Create API endpoint: `GET /api/humanness-surveys/analytics`
    - Location: `apps/api/src/routes/humanness-surveys.ts`
    - Query params: `?period=2025-Q1` (optional, default: current quarter)
    - Calculate aggregate metrics:
      - `total_responses`: Count of surveys submitted
      - `detection_mentioned_count`: Count where `question_1_detection_mentioned = true`
      - `detection_mentioned_rate = (detection_mentioned_count / total_responses) * 100`
      - `target_met = detection_mentioned_rate < 5%`
    - Return: `{ success: true, data: { period, total_responses, detection_mentioned_count, detection_mentioned_rate, target_met } }`

- [ ] **Task 8: Implement response rate tracking proxy** (AC: 7)
  - [ ] Create service: `apps/api/src/services/HumannessResponseRateService.ts`
  - [ ] Implement `calculateResponseRate(userId: string, startDate: Date, endDate: Date): Promise<ResponseRateMetrics>`:
    - Query `ai_conversation_log`:
      ```sql
      SELECT 
        COUNT(*) FILTER (WHERE direction = 'outbound' AND generated_by_ai = true) as ai_messages_sent,
        COUNT(*) FILTER (WHERE direction = 'inbound' AND created_at BETWEEN $startDate AND $endDate) as replies_received,
        (COUNT(*) FILTER (WHERE direction = 'inbound' AND created_at BETWEEN $startDate AND $endDate)::DECIMAL / 
         NULLIF(COUNT(*) FILTER (WHERE direction = 'outbound' AND generated_by_ai = true), 0) * 100) as response_rate_percentage
      FROM ai_conversation_log
      WHERE user_id = $userId
        AND created_at BETWEEN $startDate AND $endDate
      ```
    - Calculate: `response_rate_per_100 = (replies_received / ai_messages_sent) * 100`
    - Check threshold: `if response_rate_per_100 < 5%`: Flag as potential AI fatigue
    - Return: `{ ai_messages_sent, replies_received, response_rate_per_100, below_threshold: boolean, threshold: 5 }`
  - [ ] Implement `trackResponseRateTrend(userId: string, days: number = 30): Promise<ResponseRateTrend>`:
    - Query response rate for last N days, grouped by day/week
    - Calculate trend: Is response rate decreasing over time?
    - Return: `{ daily_rates: Array<{ date, response_rate }>, trend: 'increasing' | 'decreasing' | 'stable', average_rate: number }`
  - [ ] Create N8N workflow: `workflows/humanness-response-rate-monitor.json`
    - Schedule trigger: Cron `0 0 * * *` (runs daily)
    - Query all active users: `SELECT id FROM users WHERE subscription_status = 'active'`
    - For each user:
      - Call API: `GET {{ $env.API_GATEWAY_URL }}/api/humanness/response-rate?user_id={{ $json.id }}&days=30`
      - Check: `if response_rate_per_100 < 5%`:
        - Log alert to `audit_log`: `{ event_type: 'humanness_response_rate_alert', user_id, response_rate, threshold: 5 }`
        - Send notification to user (optional): "Your response rate has dropped below 5%. This may indicate AI fatigue. Consider reviewing your message strategy."
  - [ ] Create API endpoint: `GET /api/humanness/response-rate`
    - Location: `apps/api/src/routes/humanness-tests.ts` (or create `humanness.ts`)
    - Query params: `?user_id=uuid&days=30` (optional, default: 30 days)
    - Call: `HumannessResponseRateService.calculateResponseRate(userId, startDate, endDate)`
    - Return: `{ success: true, data: { ai_messages_sent, replies_received, response_rate_per_100, below_threshold, trend: {...} } }`
  - [ ] Create API endpoint: `GET /api/humanness/response-rate/trend`
    - Location: `apps/api/src/routes/humanness-tests.ts`
    - Query params: `?user_id=uuid&days=30`
    - Call: `HumannessResponseRateService.trackResponseRateTrend(userId, days)`
    - Return: `{ success: true, data: { daily_rates: [...], trend, average_rate } }`

- [ ] **Task 9: Generate TypeScript types** (AC: All)
  - [ ] Run `supabase gen types typescript` after migrations
  - [ ] Update `packages/shared/src/types/database.types.ts` with new tables
  - [ ] Create business logic types: `packages/shared/src/types/humanness.ts`
    - `HumannessTest = { id, test_name, test_version, test_type, status, target_detection_rate, ... }`
    - `TestMessage = { id, test_id, message_text, message_type, ai_prompting_strategy, channel, ... }`
    - `Panelist = { id, test_id, full_name, email, recruitment_status, ... }`
    - `TestResponse = { id, test_id, panelist_id, message_id, identified_as_ai, confidence_level, ... }`
    - `DetectionRateMetrics = { overall_detection_rate, strategy_metrics: Array<{ strategy, detection_rate, ... }>, target_met }`
    - `WinningStrategy = { strategy_name, detection_rate, ai_messages_count, ai_correctly_identified }`
    - `ResponseRateMetrics = { ai_messages_sent, replies_received, response_rate_per_100, below_threshold }`
  - [ ] Export types for use in API and frontend

- [ ] **Task 10: Write unit tests** (AC: All)
  - [ ] Create test: `apps/api/tests/unit/services/humanness-test.service.test.ts`
    - Test `createTest()` - Creates test with correct status
    - Test `addPanelist()` - Adds panelist with validation
    - Test `sendPanelistInvitation()` - Sends email and updates status
    - Test `bulkInvitePanelists()` - Handles bulk invitations
  - [ ] Create test: `apps/api/tests/unit/services/humanness-test-message.service.test.ts`
    - Test `generateAIMessagesWithStrategies()` - Generates 5 messages with different strategies
    - Test `generateHumanMessages()` - Stores human messages
    - Test `createTestMessageSet()` - Creates shuffled message set
  - [ ] Create test: `apps/api/tests/unit/services/humanness-test-analytics.service.test.ts`
    - Test `calculateDetectionRate()` - Calculates correct detection rate
    - Test `getWinningStrategy()` - Returns strategy with lowest detection rate
    - Test target threshold (<20%)
  - [ ] Create test: `apps/api/tests/unit/services/humanness-response-rate.service.test.ts`
    - Test `calculateResponseRate()` - Calculates response rate correctly
    - Test `trackResponseRateTrend()` - Tracks trend over time
    - Test threshold alert (<5%)
  - [ ] Create test: `apps/api/tests/unit/routes/humanness-tests.test.ts`
    - Test `POST /humanness-tests` - Creates test
    - Test `POST /humanness-tests/:id/panelists` - Adds panelist
    - Test `GET /humanness-tests/:id/analytics` - Returns analytics
    - Test `POST /humanness-tests/:id/codify-strategy` - Codifies winning strategy

## Dev Notes

### Architecture Context

**Humanness Testing Framework:**
- Test database schema: `humanness_tests`, `humanness_test_messages`, `humanness_test_responses`, `humanness_test_panelists`, `humanness_test_analytics`
- Panelist recruitment system for 10 B2B decision-makers (French SMB owners/founders)
- Test design: 10 messages (5 AI-generated with 5 different strategies, 5 human-written)
- Target: <20% correct AI identification rate (NFR5)
- Winning strategy codified into AI prompts and template library
- Post-launch tracking: Quarterly surveys and response rate monitoring

**Integration with Story 1.6:**
- Uses AIQualificationService to generate AI messages with different prompting strategies
- Temporarily modifies AI prompts for testing (doesn't affect production)
- Uses existing `ai_conversation_log` table for response rate tracking

**Integration with Story 1.4:**
- Codifies winning strategy into `email_templates` table
- Creates new templates based on winning strategy
- Updates template selection logic to prefer humanness-optimized templates

**Integration with Story 2.1:**
- Uses analytics infrastructure for tracking detection rates
- May use confidence scoring data for correlation analysis

**Previous Story Insights:**
From Story 1.6: AIQualificationService exists at `apps/api/src/services/ai-qualification.service.ts` with `qualifyProspect()` method. System prompt can be modified for testing. Workflow exists at `workflows/ai-conversation-agent.json`.

From Story 1.4: EmailTemplateService exists at `apps/api/src/services/email-template.service.ts` with `getTemplate()` and `personalizeTemplate()` methods. Template library in `email_templates` table.

From Story 2.1: Analytics infrastructure exists. `ai_conversation_log` table exists with `generated_by_ai`, `direction` fields for response rate tracking.

From Story 1.5.1: SMTPService exists for sending invitation emails and survey notifications.

**Testing Strategies:**
1. **Strategy 1: Baseline** - Current AIQualificationService prompt (no changes)
2. **Strategy 2: Conversational** - Casual conversation style with contractions
3. **Strategy 3: Professional but warm** - Professional tone with "I" statements, genuine interest
4. **Strategy 4: Short and direct** - Under 3 sentences, no fluff
5. **Strategy 5: Question-led** - Start with genuine business question

**Post-Launch Tracking:**
- Quarterly surveys: "Have prospects mentioned detecting automation?" (target <5% yes)
- Response rate proxy: Track reply rate per 100 messages (alert if <5% for cold outreach)
- Daily monitoring workflow checks response rates and alerts if below threshold

**File Locations:**
- Services: `apps/api/src/services/HumannessTestService.ts`, `HumannessTestMessageService.ts`, `HumannessTestAnalyticsService.ts`, `HumannessStrategyService.ts`, `HumannessResponseRateService.ts`
- Routes: `apps/api/src/routes/humanness-tests.ts`, `apps/api/src/routes/humanness-surveys.ts`
- Migrations: `supabase/migrations/YYYYMMDD_create_humanness_*.sql`
- Workflows: `workflows/humanness-survey-notifier.json`, `workflows/humanness-response-rate-monitor.json`
- Frontend (if exists): `apps/web/src/pages/HumannessTestPanelist.tsx`

### Testing

**Testing Framework:** Vitest for unit tests, manual testing for N8N workflows, Playwright for panelist interface (if frontend exists)

**Test Organization:**
- Service tests: `apps/api/tests/unit/services/humanness-*.test.ts`
- Route tests: `apps/api/tests/unit/routes/humanness-tests.test.ts`
- Integration tests: N8N workflow testing via manual execution

**Test Requirements:**
1. Test panelist recruitment: Create test, add panelists, send invitations
2. Test message generation: Generate 5 AI strategies, store human messages, create shuffled set
3. Test detection rate calculation: Calculate correct rates per strategy, identify winning strategy
4. Test strategy codification: Update AI prompts, create templates, update template selection
5. Test post-launch surveys: Quarterly notifications, survey submission, analytics
6. Test response rate tracking: Calculate rates, detect below-threshold, trend analysis
7. Test panelist interface: Message display, response submission, test completion
8. Test target thresholds: <20% detection rate, <5% survey detection mentions, <5% response rate alert

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-11 | 1.0 | Initial story creation for Epic 2: AI Safety & Quality Guardrails | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
TBD

### Completion Notes
- Story created as part of Epic 2: AI Safety & Quality Guardrails
- Implements humanness testing framework to achieve <20% AI detection rate (NFR5)
- Creates perception panel system for testing AI message quality
- Codifies winning strategy into production AI prompts and templates
- Implements post-launch tracking via surveys and response rate monitoring

