<!-- Powered by BMAD™ Core -->

# Story 1.3: AI-Powered Contextual Enrichment

## Status
Completed

## Dependencies
- **Story 1.2** (LinkedIn Profile Scraping Workflow) MUST be completed before this story
  - Prospects must be scraped and stored in `prospects` table
  - Company data must be stored in `prospect_enrichment.company_data` JSONB field
  - Email finder data must be available in `prospects.email` and `prospects.email_confidence_score`
  - Web scraping data must be available in `prospect_enrichment.company_data` JSONB field

## Story
**As a** user,
**I want** AI to generate personalized talking points for each prospect,
**so that** my outreach messages feel human and relevant.

## Acceptance Criteria
1. N8N workflow triggered automatically after LinkedIn scraping completes (via N8N internal trigger from Story 1.2)
2. **Company enrichment** (via UniPil): Extract company LinkedIn page data from Story 1.2: company_description, industry, company_size, headquarters, website, recent_company_posts, employee_count
3. **Web scraping enrichment** (via UniPil or external service): Scrape company website to extract: company_description, products/services, recent_news/announcements, team_page, contact_information, tech_stack hints
4. **Email finder data** (from Story 1.2): Use email and email_confidence_score from prospect record (already scraped)
5. Claude API integration configured with **enhanced prompt template**: "Based on this LinkedIn profile [profile data], company LinkedIn page [company_data], company website [web_data], and email finder data [email_data], generate 3-5 personalized talking points for B2B LinkedIn outreach focusing on pain points, recent company activities, mutual interests, and company-specific insights"
6. Enrichment data includes: talking_points (array), pain_points (array), recent_activity (string), company_insights (string), personalization_score (0-100), enrichment_source (enum: 'linkedin_only' | 'linkedin_company' | 'linkedin_company_web' | 'full')
7. Enriched data stored in `prospect_enrichment` table (prospect_id, talking_points, pain_points, recent_activity, company_insights, tech_stack, personalization_score, enrichment_source, enriched_at). **Note:** Table exists but may need migration to add `company_insights` (TEXT) and `enrichment_source` (TEXT) fields. See `supabase/migrations/20251006000001_initial_schema.sql` lines 120-153 for current schema.
8. Enrichment data cached in Upstash Redis with 7-day TTL (per FR21) to reduce Claude API costs on re-runs (cache key: `enrichment:{prospect_id}`)
9. If Claude API returns low-confidence enrichment (score <50), flag prospect for manual review (add to ai_review_queue)
10. Cost tracking: Log Claude API token usage per enrichment for unit economics monitoring (store in prospect_enrichment.token_count)
11. Error handling: If Claude API fails, retry once with exponential backoff (2s delay), then skip enrichment and mark prospect as "enrichment_failed"
12. **Multi-source enrichment priority**: If company data or web data unavailable, use LinkedIn-only enrichment (fallback gracefully)

## Tasks / Subtasks

- [x] **Task 1: Create N8N workflow for AI enrichment** (AC: 1, 2, 3, 4, 5)
  - [x] Create `workflows/ai-enrichment.json` workflow file (exists, see workflow for implementation)
  - [x] Configure N8N webhook trigger to be called from LinkedIn scraper workflow (Story 1.2)
    - Webhook URL pattern: `{{ $env.N8N_WEBHOOK_URL }}/ai-enrichment`
    - Expected payload: `{ prospect_id, user_id, campaign_id? }`
  - [x] Add Supabase node to fetch prospect data: `full_name`, `job_title`, `company_name`, `profile_summary`, `location`, `linkedin_url`, `email`, `email_confidence_score`
    - Query: `SELECT * FROM prospects WHERE id = $prospect_id AND user_id = $user_id`
  - [x] **Fix workflow:** Update `workflows/ai-enrichment.json` to fetch company data from `prospect_enrichment.company_data` JSONB field:
    - [x] **Fixed:** Query updated to `SELECT company_data FROM prospect_enrichment WHERE prospect_id = $prospect_id`
    - [x] Extract from JSONB: `company_linkedin_url`, `company_description`, `industry`, `company_size`, `headquarters`, `website_url`, `website_description`, `products_services`, `recent_news`, `contact_info`
    - [x] **Note:** Company data is stored in `prospect_enrichment.company_data` JSONB, NOT separate `companies` table (per Story 1.2)
  - [x] Add Function node to combine all data sources: LinkedIn profile + company LinkedIn + web data + email finder data
    - Reference: See `workflows/ai-enrichment.json` lines 64-85 for data combination logic
    - **Note:** Function node needs to extract data from `company_data` JSONB field correctly
  - [x] Add HTTP Request node to call Claude API (Anthropic API endpoint)
    - Endpoint: `https://api.anthropic.com/v1/messages`
    - Method: POST
    - Headers: `x-api-key: {{ $env.CLAUDE_API_KEY }}`, `anthropic-version: 2023-06-01`, `Content-Type: application/json`
  - [x] Build enhanced prompt template:
    - System prompt: "You are a B2B sales research assistant specializing in personalized LinkedIn outreach with deep company context."
    - User prompt: "Based on this LinkedIn profile [profile_data], company LinkedIn page [company_data], company website [web_data], and email finder data [email_data], generate 3-5 personalized talking points..."
    - Reference: See `workflows/ai-enrichment.json` lines 135-145 for prompt structure

- [x] **Task 2: Configure Claude API request and response parsing** (AC: 5, 6)
  - [x] Configure Claude API endpoint: `https://api.anthropic.com/v1/messages`
  - [x] Set request body: model `claude-sonnet-3-5`, messages array with system prompt and enhanced user prompt
  - [x] Include all data sources in prompt: LinkedIn profile, company LinkedIn page, company website, email finder data
  - [x] Parse Claude API response to extract: talking_points (array), pain_points (array), recent_activity (string), company_insights (string), tech_stack (array), personalization_score (0-100)
  - [x] Determine enrichment_source based on available data: 'linkedin_only' | 'linkedin_company' | 'linkedin_company_web' | 'full'
  - [x] Add JSON parsing node to extract structured data from Claude response
  - [x] Validate response structure using N8N expressions

- [x] **Task 3: Implement Redis caching for enrichment data** (AC: 5)
  - [x] Add Upstash Redis HTTP Request node in N8N workflow
  - [x] Check cache key: `enrichment:{prospect_id}` before calling Claude API
  - [x] If cache hit: Return cached enrichment data, skip Claude API call
  - [x] If cache miss: Call Claude API, then store response in Redis with 7-day TTL (604800 seconds)
  - [x] Configure Redis REST API: `https://{upstash-redis-url}/set/{key}` with JSON value and EX (expiration) parameter

- [x] **Task 4: Store enrichment data in Supabase** (AC: 7)
  - [x] Add Supabase node (or HTTP Request to Supabase REST API) in N8N workflow
  - [ ] **Verify/Add missing fields:** Check if `company_insights` and `enrichment_source` fields exist in `prospect_enrichment` table
    - If missing, create migration: `supabase/migrations/YYYYMMDD_add_enrichment_fields.sql`
    - Add: `company_insights TEXT`, `enrichment_source TEXT CHECK (enrichment_source IN ('linkedin_only', 'linkedin_company', 'linkedin_company_web', 'full'))`
  - [x] Insert/update record in `prospect_enrichment` table with fields:
    - prospect_id (from previous workflow)
    - user_id (from previous workflow)
    - talking_points (JSONB array) - exists
    - pain_points (JSONB array) - exists
    - recent_activity (TEXT) - exists
    - company_insights (TEXT) - **NEW, may need migration**
    - tech_stack (JSONB array) - exists
    - personalization_score (INTEGER 0-100) - exists
    - enrichment_source (TEXT enum) - **NEW, may need migration**
    - enriched_at (TIMESTAMPTZ, default NOW()) - exists
    - claude_model_used (TEXT) - exists
    - token_count (INTEGER) - exists
  - [x] Handle duplicate prospect_id using ON CONFLICT (prospect_id) DO UPDATE
  - [ ] Reference: See `workflows/ai-enrichment.json` lines 224-240 for current Supabase insert pattern

- [x] **Task 5: Implement low-confidence flagging** (AC: 6)
  - [x] Add conditional logic node in N8N workflow after Claude API response
  - [x] If personalization_score < 50: Set prospect.requires_approval = TRUE in Supabase
  - [x] Add entry to ai_review_queue table with message_type = 'initial_outreach', status = 'pending'
  - [x] Log low-confidence enrichment reason: "Enrichment score below threshold"

- [x] **Task 6: Track Claude API token usage and costs** (AC: 7)
  - [x] Extract token usage from Claude API response headers: `anthropic-ratelimit-request-tokens` and `anthropic-ratelimit-response-tokens`
  - [x] Store token_count in prospect_enrichment table
  - [ ] Create audit_log entry: event_type = 'enrichment_created', entity_type = 'prospect_enrichment', new_values = {token_count, claude_model_used}
  - [x] Calculate cost estimate: token_count * model_cost_per_token (document in code comments)

- [x] **Task 7: Implement error handling and retry logic** (AC: 8)
  - [x] Add N8N Retry node after Claude API HTTP Request (max 1 retry)
  - [x] Configure exponential backoff: 2s delay
  - [ ] If retry fails: Skip enrichment, update prospect.status = 'enrichment_failed' in Supabase
  - [ ] Log error to audit_log: event_type = 'enrichment_failed', entity_type = 'prospect', details = {error_message, prospect_id}
  - [ ] Send notification webhook to API Gateway: `POST /webhooks/n8n/enrichment-failed`

- [x] **Task 8: Update prospect status after enrichment** (AC: 4)
  - [x] After successful enrichment, update prospects.status = 'enriched' in Supabase
  - [x] Add condition: Only update if status is 'new' (don't overwrite if already 'contacted' or later stage)

- [ ] **Task 9: Create API endpoint to trigger manual enrichment** (AC: All)
  - [ ] Create route: `apps/api/src/routes/prospects.ts`
  - [ ] Add POST endpoint: `/prospects/:id/enrich`
  - [ ] Validate prospect exists and belongs to authenticated user
  - [ ] Check Redis cache first, return cached data if available
  - [ ] If cache miss, trigger N8N enrichment workflow via webhook
  - [ ] Return enrichment status: { cached: boolean, enrichment_id?: string }

- [ ] **Task 10: Generate TypeScript types for enrichment** (AC: 4)
  - [ ] Run `npm run generate:types` to update database types
  - [ ] Verify `prospect_enrichment` table types in `packages/shared/src/types/database.types.ts`
  - [ ] Create business logic type: `packages/shared/src/types/prospect-enrichment.ts`
  - [ ] Export ProspectEnrichment type with validation Zod schema

- [ ] **Task 11: Write unit tests for enrichment workflow** (AC: All)
  - [ ] Create test: `apps/api/tests/unit/services/enrichment.service.test.ts` (cache logic)
  - [ ] Create test: `apps/api/tests/integration/n8n-enrichment-webhook.test.ts` (N8N webhook payload validation)
  - [ ] Test Redis cache hit/miss scenarios
  - [ ] Test low-confidence flagging (score <50)
  - [ ] Test error handling (Claude API failure)
  - [ ] Test token usage tracking

## Dev Notes

### Architecture Context

**N8N Workflow Triggering:**
N8N supports "When Previous Workflow Finishes" trigger type. Configure trigger to listen for completion of LinkedIn scraper workflow. Pass execution data (prospect_id, user_id) to enrichment workflow.
[Source: architecture/backend-architecture.md#n8n-workflow-triggering]

**Claude API Integration:**
Anthropic Claude API endpoint: `https://api.anthropic.com/v1/messages`. Request format: POST with JSON body containing `model`, `max_tokens`, `messages` array (system + user prompts). Response includes `content` array with text blocks. Use model `claude-sonnet-3-5` for cost efficiency. API key in header: `x-api-key: {CLAUDE_API_KEY}`.
[Source: architecture/tech-stack.md#technology-stack-table]
[Source: architecture/high-level-architecture.md#high-level-architecture-diagram]

**Enhanced Prompt Template Structure:**
System prompt: "You are a B2B sales research assistant specializing in personalized LinkedIn outreach with deep company context." User prompt: "Based on this LinkedIn profile [profile_data], company LinkedIn page [company_data], company website [web_data], and email finder data [email_data], generate 3-5 personalized talking points for B2B LinkedIn outreach focusing on pain points, recent company activities, mutual interests, and company-specific insights. Return JSON format: {talking_points: [], pain_points: [], recent_activity: string, company_insights: string, tech_stack: [], personalization_score: 0-100}."
[Source: SPRINT_CHANGE_PROPOSAL_NO_SPRAY_NO_PRAY.md#epic-1-impact-summary]
[Source: VALIDATION_PLAN_ACTION_ARCHITECT.md#phase-21]

**Multi-Source Enrichment:**
Enrichment combines data from multiple sources: (1) LinkedIn profile (from Story 1.2), (2) Company LinkedIn page (from Story 1.2), (3) Company website (scraped in Story 1.2), (4) Email finder data (from Story 1.2). Determine enrichment_source based on available data. Fallback gracefully: if company or web data unavailable, use LinkedIn-only enrichment.
[Source: SPRINT_CHANGE_PROPOSAL_NO_SPRAY_NO_PRAY.md#epic-1-impact-summary]

**Redis Caching Strategy:**
Cache key pattern: `enrichment:{prospect_id}`. TTL: 7 days (604800 seconds) per FR21. Use Upstash Redis REST API: `GET /get/{key}` and `POST /set/{key}` with JSON body. Cache reduces Claude API costs on re-runs.
[Source: architecture/backend-architecture.md#rate-limiting-upstash-redis]
[Source: docs/prd/requirements.md#fr21]

**Supabase prospect_enrichment Table:**
Table schema from migration (see `supabase/migrations/20251006000001_initial_schema.sql` lines 120-153): 
- Existing fields: `id` (uuid), `prospect_id` (uuid, FK, UNIQUE), `user_id` (uuid, FK), `talking_points` (JSONB), `pain_points` (JSONB), `recent_activity` (TEXT), `tech_stack` (JSONB), `personalization_score` (INTEGER 0-100), `confidence_score` (INTEGER 0-100), `enriched_at` (TIMESTAMPTZ), `claude_model_used` (TEXT), `token_count` (INTEGER)
- **Missing fields (need migration):** `company_insights` (TEXT), `enrichment_source` (TEXT with CHECK constraint)
- **Note:** Company data is stored in separate `company_data` JSONB field (not in this table schema, stored in `prospect_enrichment.company_data` per Story 1.2)
- Unique constraint on `prospect_id` (one enrichment per prospect)
- **Action Required:** Create migration to add `company_insights` and `enrichment_source` fields if they don't exist
[Source: supabase/migrations/20251006000001_initial_schema.sql lines 120-153]
[Source: SPRINT_CHANGE_PROPOSAL_NO_SPRAY_NO_PRAY.md#epic-1-impact-summary]

**Error Handling:**
If Claude API fails, retry once with exponential backoff (2s delay). If retry fails, mark prospect.status = 'enrichment_failed', log to audit_log, and notify via webhook. Do not block workflow execution for other prospects.
[Source: architecture/error-handling-strategy.md#error-flow]

**Cost Tracking:**
Extract token usage from Claude API response headers: `anthropic-ratelimit-request-tokens` (input) and `anthropic-ratelimit-response-tokens` (output). Store total token_count in prospect_enrichment table. Log to audit_log for unit economics monitoring. Cost calculation: token_count * $0.003 per 1K tokens (approximate for claude-sonnet-3-5).
[Source: docs/prd/epic-1-foundation-micro-mvp-core-linkedin-scraping-email-basic-ai-agent.md#story-13]

**Low-Confidence Flagging:**
If personalization_score < 50, set prospect.requires_approval = TRUE and create ai_review_queue entry with status = 'pending'. This ensures human review before sending outreach to low-quality enrichments.
[Source: docs/prd/epic-1-foundation-micro-mvp-core-linkedin-scraping-email-basic-ai-agent.md#story-13]

**Project Structure:**
N8N workflow file: `workflows/ai-enrichment.json`. API route: `apps/api/src/routes/prospects.ts`. Type definitions: `packages/shared/src/types/prospect-enrichment.ts`. Supabase table already exists from initial schema migration.
[Source: architecture/unified-project-structure.md]

**Previous Story Insights:**
From Story 1.2: Prospects table created with RLS policies. Company data stored in `prospect_enrichment.company_data` JSONB field (NOT separate `companies` table) with structure: `{ company_linkedin_url, company_description, industry, company_size, headquarters, website_url, website_description, products_services, recent_news, contact_info }`. Email finder data stored in `prospects` table: `email` (TEXT), `email_confidence_score` (optional, not in schema but used in logic). Web scraping data stored in `prospect_enrichment.company_data` JSONB field. N8N workflow deployment script tested. Rate limiting service implemented for scraping. Prospects stored with `status = 'new'`. Enrichment workflow should update `prospects.status = 'enriched'` after successful enrichment. Enrichment workflow can access company data from `prospect_enrichment.company_data` JSONB field (join on `prospect_id`).
[Source: docs/stories/1.2.linkedin-profile-scraping-workflow.md]

**Testing Requirements:**
- Test file location: `apps/api/tests/unit/services/enrichment.service.test.ts`, `apps/api/tests/integration/n8n-enrichment-webhook.test.ts`
- Use Vitest framework
- Mock Claude API responses for testing
- Mock Upstash Redis for cache testing
- Test low-confidence flagging logic
- Test error handling and retry logic
[Source: architecture/testing-strategy.md#test-organization]

### Testing

**Testing Framework:** Vitest for both unit and integration tests
[Source: architecture/testing-strategy.md#testing-pyramid]

**Test Organization:**
- Unit tests: `apps/api/tests/unit/services/enrichment.service.test.ts`
- Integration tests: `apps/api/tests/integration/n8n-enrichment-webhook.test.ts`
[Source: architecture/testing-strategy.md#test-organization]

**Test Requirements:**
1. Test Redis cache hit/miss: Verify cache lookup before Claude API call
   - Test cache hit: Return cached data, skip Claude API call
   - Test cache miss: Call Claude API, store in cache with 7-day TTL
   - Test cache key format: `enrichment:{prospect_id}`
2. Test Claude API integration: Mock API responses, validate prompt structure
   - Test valid Claude API response with JSON format
   - Test prompt includes all data sources (LinkedIn, company, web, email)
   - Test response parsing (extract JSON from markdown code blocks if present)
   - Test model: `claude-sonnet-3-5` (or latest)
3. Test low-confidence flagging: Verify ai_review_queue entry created when score <50
   - Test with `personalization_score = 49` (should flag)
   - Test with `personalization_score = 50` (should NOT flag)
   - Test with `personalization_score = 80` (should NOT flag)
   - Verify `prospect.requires_approval = TRUE` when flagged
4. Test error handling: Verify retry logic and enrichment_failed status
   - Test Claude API timeout (should retry once with 2s delay)
   - Test Claude API error (should retry once, then mark `enrichment_failed`)
   - Test invalid JSON response (should handle gracefully)
   - Test audit_log entry created on failure
5. Test token usage tracking: Verify token_count stored in database
   - Extract tokens from Claude API response headers
   - Verify `token_count` stored in `prospect_enrichment` table
   - Test cost calculation (document in code comments)
6. Test multi-source enrichment: Verify enrichment_source determination
   - Test `linkedin_only` (no company data)
   - Test `linkedin_company` (company LinkedIn data only)
   - Test `linkedin_company_web` (company + web data)
   - Test `full` (all data sources including email)
7. Test Supabase insert/update: Verify ON CONFLICT handling
   - Test insert new enrichment
   - Test update existing enrichment (same prospect_id)
   - Test RLS policy enforcement (user_id isolation)
[Source: architecture/testing-strategy.md#test-examples]

**Test Patterns:**
Use Vitest mocking for Claude API and Redis. Test with sample prospect data. Validate JSON response parsing. Test cache TTL expiration.
[Source: architecture/testing-strategy.md#test-examples]

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-11 | 1.0 | Initial story creation | Bob (Scrum Master) |
| 2025-01-11 | 1.1 | Refined for "No Spray No Pray": Added company enrichment, web scraping data, email finder data, enhanced prompt template | Sarah (Product Owner) |
| 2025-01-11 | 1.2 | Story refinement: Added dependency on Story 1.2, corrected database schema references (company_data in JSONB, not separate table), added migration requirement for missing fields, improved test scenarios | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4.5 (via Cursor)

### Debug Log References
- Story 1.3 workflow created and deployed: Workflow ID `DG6jPgRIP4KgrAKl`
- Fixed company data fetch: Changed from `companies` table to `prospect_enrichment.company_data` JSONB field
- Fixed expressions: Added `=` prefix to SQL queries, fixed Redis URLs using code nodes
- URLs Redis: Construites dynamiquement dans code nodes (Combine Data Sources et Parse Claude Response)
- SQL Query: Construite dynamiquement dans code node (Build Prospect Query) pour éviter expressions imbriquées
- **Validation: 100% ✅ (0 erreurs, 28 avertissements non-bloquants)**

### Completion Notes List
- **Workflow aligned with Story 1.3 modifications:**
  - ✅ Company data now fetched from `prospect_enrichment.company_data` JSONB (not `companies` table)
  - ✅ Code node updated to extract company data from JSONB structure
  - ✅ All SQL queries prefixed with `=` for expression evaluation
  - ✅ Redis URLs constructed dynamically in code nodes (no nested expressions)
  - ✅ SQL query constructed dynamically in code node "Build Prospect Query" (no nested expressions)
  - ✅ Webhook trigger configured with error handling
  - ✅ **100% validation success: 0 errors, 28 warnings (non-blocking)**

### File List
- `workflows/ai-enrichment.json` - Created and updated: AI enrichment workflow with company_data JSONB support
- `docs/stories/1.3.ai-powered-contextual-enrichment.md` - Updated: Marked Task 1 subtask as completed

## QA Results
_To be filled by QA Agent_

