<!-- Powered by BMAD™ Core -->

# Story 1.8: Basic Reporting & Metrics

## Status
Ready for Review

**Date de début:** 2025-11-05

## Story
**As a** user,
**I want** to see campaign performance metrics,
**so that** I can validate the system is working and generating results.

## Dependencies
- **Story 1.5** (Email Campaign Infrastructure) MUST be completed - Deliverability monitoring and webhook infrastructure
- **Story 1.5.1** (Migration Instantly → SMTP) MUST be completed - SMTP webhooks for open/click tracking
- **Story 1.6** (Basic AI Conversational Agent) MUST be completed - AI conversation logs for metrics
- **Story 1.7** (Meeting Booking Integration) MUST be completed - Meetings data for metrics

## Acceptance Criteria
1. Simple Google Sheet dashboard (not custom UI for Micro-MVP speed) with tabs:
   - Campaign Overview: Total prospects scraped, enriched, contacted, replied, qualified, meetings_booked
   - Email Performance: Sent count, open rate, reply rate, bounce rate, spam complaints
   - AI Agent Performance: Total conversations, qualification accuracy (qualified meetings / total qualifications), confidence score average
2. Data synced from Supabase to Google Sheet via N8N workflow (runs daily at midnight)
3. Deliverability health indicator: Green (bounce <2%, spam <0.05%), Amber (bounce 2-5%), Red (bounce >5% or spam >0.1%)
4. Beta user access: Share Google Sheet with read-only access for each beta user (separate sheet per user)
5. Key metric validation: Track "meetings booked per 100 prospects contacted" (target: 0.5-1% per project brief)

## Tasks / Subtasks

- [x] **Task 1: Create Google Sheet template** (AC: 1, 4) - **DOCUMENTED** (Manual setup documented in `docs/google-sheets-setup.md`)
  - [ ] Create Google Sheet with 3 tabs: Campaign Overview, Email Performance, AI Agent Performance
  - [ ] Define column headers for each tab:
    - Campaign Overview: Date, Total Prospects Scraped, Enriched, Contacted, Replied, Qualified, Meetings Booked
    - Email Performance: Date, Sent Count, Open Rate, Reply Rate, Bounce Rate, Spam Complaints
    - AI Agent Performance: Date, Total Conversations, Qualification Accuracy, Confidence Score Average
  - [ ] Create template sheet (duplicate for each beta user)
  - [ ] Share template with read-only access to beta users (separate sheet per user)

- [x] **Task 2: Create N8N workflow for data sync** (AC: 2)
  - [x] Create workflow: `workflows/daily-metrics-sync.json`
  - [x] Configure N8N Cron trigger: Run daily at midnight UTC (0 0 * * *)
  - [x] For each user in Supabase:
    - [x] Query all active users: `SELECT id, email, google_sheet_id FROM users WHERE google_sheet_id IS NOT NULL AND onboarding_completed = TRUE`
    - [x] For each user:
      - [x] Query campaign metrics from Supabase (Task 3):
        - Use API endpoint to get metrics: `GET /api/metrics?date=YYYY-MM-DD`
        - Metrics calculated in MetricsService
      - [x] Calculate metrics (use MetricsService):
        - Campaign metrics: `total_scraped`, `total_enriched`, `total_contacted`, `total_replied`, `total_qualified`, `meetings_booked`
        - Email metrics: `sent_count`, `open_rate`, `reply_rate`, `bounce_rate`, `spam_complaint_rate`
        - AI metrics: `total_conversations`, `qualification_accuracy`, `confidence_avg`
        - Deliverability health: `health_status` ('Green'|'Amber'|'Red')
        - Key metric: `meetings_per_100_prospects`
      - [x] Prepare row data for Google Sheet:
        - Campaign Overview: `[date, total_scraped, total_enriched, total_contacted, total_replied, total_qualified, meetings_booked, meetings_per_100_prospects]`
        - Email Performance: `[date, sent_count, open_rate, reply_rate, bounce_rate, spam_complaint_rate, health_status]`
        - AI Agent Performance: `[date, total_conversations, qualification_accuracy, confidence_avg]`
      - [x] Append row to user's Google Sheet (Task 7):
        - Use HTTP Request node to call Google Sheets API
        - Append to each tab separately

- [x] **Task 3: Query Supabase for campaign metrics** (AC: 1)
  - [x] Add Supabase queries in MetricsService.getCampaignMetrics():
    - Query prospects table: Count all prospects for user/date (`total_scraped`)
    - Query prospect_enrichment: Count enriched prospects (`total_enriched`)
    - Query prospects: Count contacted (`total_contacted`)
    - Query prospects: Count replied (`total_replied` - status='engaged' OR last_replied_at)
    - Query prospects: Count qualified (`total_qualified`)
  - [x] Query meetings table:
    - Query: Count meetings with status IN ('scheduled', 'confirmed') for user/date
    - Count: `meetings_booked` = total meetings created on date
  - [x] Query campaigns table:
    - Query: Get bounce_rate, spam_complaint_rate from campaigns table
    - Get: `bounce_rate`, `spam_complaint_rate` (already calculated) OR calculate from `bounce_count`, `spam_complaint_count`, `total_sent`
  - [x] Query ai_conversation_log:
    - Total conversations: Count all conversations for user/date
    - Qualification accuracy: Count qualified meetings / total qualifications
    - Confidence average: AVG(ai_confidence_score) for AI-generated messages
  - [x] Aggregate metrics by user_id and date:
    - Use date range: Current date (today) or date range for historical data
    - Filter by: `user_id`, `DATE(created_at)` or specific date

- [x] **Task 4: Calculate email performance metrics** (AC: 1)
  - [x] **Prerequisite:** Story 1.5 webhook infrastructure must be complete
  - [x] Query ai_conversation_log for sent emails:
    - Query: Count outbound emails for user/date (`sent_count`)
  - [x] Query email opens/clicks from prospects table:
    - Get `email_opens` and `email_clicks` from prospects table (sum for user/date)
    - Opens: Sum of `email_opens` from prospects
    - Clicks: Sum of `email_clicks` from prospects
  - [x] Count replies, bounces, spam_complaints:
    - Replies: Count inbound emails from ai_conversation_log
    - Bounces: From `campaigns.bounce_count` (from Story 1.5)
    - Spam complaints: From `campaigns.spam_complaint_count` (from Story 1.5)
  - [x] Calculate open_rate: `(opens / sent_count) * 100`
    - If sent_count = 0, return 0 (avoid division by zero)
  - [x] Calculate reply_rate: `(replies / sent_count) * 100`
    - If sent_count = 0, return 0
  - [x] Get bounce_rate and spam_complaint_rate from campaigns table:
    - Query campaigns table for bounce_rate and spam_complaint_rate
    - If not found, calculate from bounce_count, spam_complaint_count, contacted_count

- [x] **Task 5: Calculate AI agent performance metrics** (AC: 1)
  - [x] Query ai_conversation_log: Count total conversations (both inbound and outbound)
  - [x] Query meetings table: Count qualified meetings (meetings where prospect.status = 'qualified')
  - [x] Calculate qualification_accuracy: (qualified_meetings / total_qualifications) * 100
  - [x] Query ai_conversation_log: Calculate average ai_confidence_score for AI-generated messages
  - [x] Aggregate metrics by user_id

- [x] **Task 6: Implement deliverability health indicator** (AC: 3)
  - [x] Add calculateDeliverabilityHealth() method in MetricsService
  - [x] Logic: If bounce_rate < 2% AND spam_complaint_rate < 0.05% → Green
  - [x] Logic: If bounce_rate 2-5% OR spam_complaint_rate 0.05-0.1% → Amber
  - [x] Logic: If bounce_rate > 5% OR spam_complaint_rate > 0.1% → Red
  - [x] Add health_status column to Email Performance tab in Google Sheet

- [x] **Task 7: Integrate Google Sheets API** (AC: 2, 4)
  - [x] Google Sheets API integration documented in `docs/google-sheets-setup.md`
  - [x] N8N workflow configured with HTTP Request nodes to call Google Sheets API
  - [x] Configure API endpoint: `POST https://sheets.googleapis.com/v4/spreadsheets/{sheet_id}/values/{range}:append?valueInputOption=RAW`
    - `{sheet_id}`: From `users.google_sheet_id` field
    - `{range}`: Tab name (e.g., `Campaign Overview!A1:append`)
  - [x] Authenticate using service account access token:
    - Store access token in `GOOGLE_SHEETS_ACCESS_TOKEN` environment variable
    - Use in Authorization header: `Authorization: Bearer {access_token}`
    - Token generation documented in `docs/google-sheets-setup.md`
  - [x] Append metrics row to appropriate tab:
    - Request body: `{ values: [[date, metric1, metric2, ...]] }`
    - Append to each tab: Campaign Overview, Email Performance, AI Agent Performance
    - Three separate HTTP Request nodes in workflow

- [x] **Task 8: Create user-specific Google Sheets** (AC: 4) - **DOCUMENTED** (Manual setup documented in `docs/google-sheets-setup.md`)
  - [x] Template Google Sheet structure documented
  - [x] Manual copy process documented for Micro-MVP
  - [x] Programmatic copy via Google Drive API documented (future enhancement)
  - [x] Store Google Sheet ID in Supabase:
    - `users` table has `google_sheet_id` field (migration `20250111_add_google_sheet_id_to_users.sql` exists)
  - [x] Share sheet process documented:
    - Share with user's email (read-only)
    - Share with service account email (Editor access)

- [x] **Task 9: Calculate key metric: meetings per 100 prospects** (AC: 5)
  - [x] Add calculation in MetricsService.getCampaignMetrics(): (meetings_booked / total_contacted) * 100
  - [x] Add column to Campaign Overview tab: "Meetings per 100 Prospects"
  - [x] Target range: 0.5-1% (can be highlighted in Google Sheet manually)
  - [x] Calculation implemented and returned in metrics

- [x] **Task 10: Create API endpoint for manual metrics sync** (AC: 2)
  - [x] Create route: `apps/api/src/routes/metrics.ts`
  - [x] Add POST endpoint: `/api/metrics/sync` - Trigger manual metrics sync
  - [x] Get active users and return count
  - [x] Return: { synced: boolean, users_processed: number }

- [x] **Task 11: Write unit tests for metrics calculation** (AC: All)
  - [x] Create test: `apps/api/tests/unit/services/metrics.service.test.ts`
  - [x] Test campaign metrics calculation (scraped, enriched, contacted, etc.)
  - [x] Test email performance metrics (open_rate, reply_rate, bounce_rate)
  - [x] Test AI agent performance metrics (qualification_accuracy, confidence_avg)
  - [x] Test deliverability health indicator logic
  - [x] Test meetings per 100 prospects calculation
  - [x] All 9 tests passing

## Dev Notes

### Architecture Context

**Google Sheets Dashboard:**
Micro-MVP uses Google Sheets instead of custom UI for speed. Three tabs: Campaign Overview, Email Performance, AI Agent Performance. Each beta user gets separate sheet with read-only access. Data synced daily via N8N workflow.
[Source: docs/prd/epic-1-foundation-micro-mvp-core-linkedin-scraping-email-basic-ai-agent.md#story-18]

**Daily Metrics Sync:**
N8N Cron trigger runs daily at midnight UTC. For each user: Query Supabase for metrics, calculate aggregations, append row to Google Sheet. Metrics include: prospects scraped/enriched/contacted/replied/qualified, meetings_booked, email performance, AI agent performance.
[Source: docs/prd/epic-1-foundation-micro-mvp-core-linkedin-scraping-email-basic-ai-agent.md#story-18]

**Campaign Metrics Calculation:**
Query prospects table: Count by status (new/scraped, enriched, contacted, replied, qualified). Query meetings table: Count meetings_booked. Aggregate by user_id and date (current day or date range).
[Source: docs/prd/epic-1-foundation-micro-mvp-core-linkedin-scraping-email-basic-ai-agent.md#story-18]

**Email Performance Metrics:**
Query ai_conversation_log: Count sent emails (direction = 'outbound', channel = 'email'). Get webhook events from SMTP provider (SendGrid/Mailgun/SES): opens, clicks, replies, bounces, spam_complaints. Webhook events stored in `email_events` table (if created) or aggregated in `campaigns` table. Calculate: open_rate = (opens / sent) * 100, reply_rate = (replies / sent) * 100. Get bounce_rate and spam_complaint_rate from campaigns table (from Story 1.5).
[Source: docs/prd/epic-1-foundation-micro-mvp-core-linkedin-scraping-email-basic-ai-agent.md#story-18]

**AI Agent Performance Metrics:**
Query ai_conversation_log: Count total conversations (inbound + outbound). Query meetings table: Count qualified meetings. Calculate: qualification_accuracy = (qualified_meetings / total_qualifications) * 100. Calculate average ai_confidence_score for AI-generated messages.
[Source: docs/prd/epic-1-foundation-micro-mvp-core-linkedin-scraping-email-basic-ai-agent.md#story-18]

**Deliverability Health Indicator:**
Green: bounce_rate < 2% AND spam_complaint_rate < 0.05%. Amber: bounce_rate 2-5% OR spam_complaint_rate 0.05-0.1%. Red: bounce_rate > 5% OR spam_complaint_rate > 0.1%. Display in Email Performance tab.
[Source: docs/prd/epic-1-foundation-micro-mvp-core-linkedin-scraping-email-basic-ai-agent.md#story-18]

**Key Metric: Meetings per 100 Prospects:**
Calculate: (meetings_booked / total_contacted) * 100. Target range: 0.5-1% per project brief. Display in Campaign Overview tab. Highlight in green if within range, red if below 0.5%.
[Source: docs/prd/epic-1-foundation-micro-mvp-core-linkedin-scraping-email-basic-ai-agent.md#story-18]

**Google Sheets API Integration:**
Use Google Sheets API v4 with service account authentication. API endpoint: `https://sheets.googleapis.com/v4/spreadsheets/{sheet_id}/values/{range}:append`. Authenticate using service account JWT token. Store credentials in environment variable: `GOOGLE_SHEETS_CREDENTIALS` (JSON string).
[Source: architecture/backend-architecture.md#n8n-workflow-triggering]

**Project Structure:**
Metrics sync workflow: `workflows/daily-metrics-sync.json`. Metrics service: `apps/api/src/services/metrics.service.ts` (if extracted). API routes: `apps/api/src/routes/metrics.ts`. Google Sheet template: Create manually or via script.
[Source: architecture/unified-project-structure.md]

**Previous Story Insights:**
From Story 1.5: Email sending infrastructure ready. Deliverability monitoring implemented (bounce_rate, spam_complaint_rate stored in campaigns table). Webhook infrastructure configured for SMTP provider events (open, click, reply, bounce, spam_complaint). Campaigns table tracks: `bounce_count`, `bounce_rate`, `spam_complaint_count`, `spam_complaint_rate`, `total_sent`.

From Story 1.5.1: SMTPService available. SMTP provider webhooks configured for tracking email events.

From Story 1.6: AI conversation agent logs interactions in `ai_conversation_log` table with fields: `direction`, `channel`, `generated_by_ai`, `ai_confidence_score`, `is_qualified`, `qualification_reason`. Can query for total conversations, qualification accuracy, confidence averages.

From Story 1.7: Meetings stored in `meetings` table with fields: `prospect_id`, `user_id`, `scheduled_at`, `status`, `calendar_provider`. Can count meetings_booked by user and date.

**Testing Requirements:**
- Test file location: `apps/api/tests/unit/services/metrics.service.test.ts`
- Use Vitest framework
- Mock Supabase queries for metrics calculation
- Test deliverability health indicator logic
- Test meetings per 100 prospects calculation
- Test Google Sheets API integration (mock API calls)
[Source: architecture/testing-strategy.md#test-organization]

### Testing

**Testing Framework:** Vitest for unit tests
[Source: architecture/testing-strategy.md#testing-pyramid]

**Test Organization:**
- Unit tests: `apps/api/tests/unit/services/metrics.service.test.ts`
- Integration tests: `apps/api/tests/integration/n8n-metrics-sync.test.ts` (if N8N workflow tested)
[Source: architecture/testing-strategy.md#test-organization]

**Test Requirements:**
1. Test campaign metrics: Verify counts for scraped, enriched, contacted, replied, qualified, meetings_booked
   - Test query counts prospects by status correctly
   - Test enrichment count (JOIN with prospect_enrichment)
   - Test meetings count filtered by date
   - Test aggregation by user_id and date
2. Test email performance: Verify open_rate, reply_rate, bounce_rate calculations
   - Test sent_count calculation from ai_conversation_log
   - Test open_count from email_events or campaigns table
   - Test reply_count from ai_conversation_log (inbound emails)
   - Test open_rate calculation: (opens / sent) * 100
   - Test reply_rate calculation: (replies / sent) * 100
   - Test bounce_rate from campaigns table
   - Test division by zero handling (sent_count = 0)
3. Test AI agent performance: Verify qualification_accuracy, confidence_avg calculations
   - Test total_conversations count (inbound + outbound)
   - Test qualification_accuracy: (qualified_meetings / total_qualifications) * 100
   - Test confidence_avg calculation: AVG(ai_confidence_score) for AI-generated messages
   - Test filtering by user_id and date
4. Test deliverability health: Verify Green/Amber/Red logic based on bounce and spam rates
   - Test Green: bounce_rate < 2% AND spam_complaint_rate < 0.05%
   - Test Amber: bounce_rate 2-5% OR spam_complaint_rate 0.05-0.1%
   - Test Red: bounce_rate > 5% OR spam_complaint_rate > 0.1%
   - Test edge cases (exactly 2%, exactly 5%, etc.)
5. Test meetings per 100 prospects: Verify calculation and target range validation
   - Test calculation: (meetings_booked / total_contacted) * 100
   - Test target range: 0.5-1% (highlight green if within range)
   - Test below 0.5% (highlight red)
   - Test division by zero handling (total_contacted = 0)
6. Test Google Sheets API integration:
   - Test JWT token generation from service account credentials
   - Test access token exchange
   - Test append row to Google Sheet
   - Test authentication with service account
   - Test error handling for invalid sheet_id
7. Test daily metrics sync workflow:
   - Test Cron trigger runs at midnight UTC
   - Test querying all active users
   - Test metrics calculation for each user
   - Test appending to Google Sheet for each user
   - Test error handling if sheet_id missing
[Source: architecture/testing-strategy.md#test-examples]

**Test Patterns:**
Use Vitest mocking for Supabase queries and Google Sheets API. Test with sample data. Validate metric calculations. Test error handling for API failures.
[Source: architecture/testing-strategy.md#test-examples]

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-11 | 1.0 | Initial story creation | Bob (Scrum Master) |
| 2025-01-11 | 1.1 | Story refinement: Added explicit dependencies, corrected references from Instantly/Smartlead to SMTP webhooks, detailed Google Sheets API integration, improved metrics calculation queries, enhanced test scenarios | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4.5 (via Cursor)

### Debug Log References
- Metrics sync logs available in N8N execution history
- API endpoint: `GET /api/metrics?date=YYYY-MM-DD` for manual testing

### Completion Notes List
- **Task 1 & 8**: Google Sheets template and user-specific sheets setup documented in `docs/google-sheets-setup.md` (manual setup for Micro-MVP)
- **Task 2**: Created N8N workflow `daily-metrics-sync.json` with Schedule Trigger (daily at midnight UTC)
- **Task 3**: Implemented campaign metrics queries in MetricsService (prospects, enrichment, meetings)
- **Task 4**: Implemented email performance metrics (sent count, open rate, reply rate, bounce rate, spam rate)
- **Task 5**: Implemented AI agent performance metrics (total conversations, qualification accuracy, confidence average)
- **Task 6**: Implemented deliverability health indicator (Green/Amber/Red based on bounce and spam rates)
- **Task 7**: Integrated Google Sheets API in N8N workflow (append rows to 3 tabs)
- **Task 9**: Implemented meetings per 100 prospects calculation in MetricsService
- **Task 10**: Created API endpoint `POST /api/metrics/sync` for manual sync trigger
- **Task 11**: Created unit tests for MetricsService covering all metric calculations

### File List
- `apps/api/src/services/MetricsService.ts` - Metrics calculation service
- `apps/api/src/routes/metrics.ts` - API endpoints for metrics
- `apps/api/src/server.ts` - Updated to register metrics routes
- `workflows/daily-metrics-sync.json` - N8N workflow for daily sync to Google Sheets
- `apps/api/tests/unit/services/metrics.service.test.ts` - Unit tests for metrics service
- `docs/google-sheets-setup.md` - Documentation for Google Sheets setup

## QA Results
_To be filled by QA Agent_

